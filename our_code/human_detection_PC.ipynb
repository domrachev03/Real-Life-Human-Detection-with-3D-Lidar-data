{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d25cf692",
      "metadata": {
        "id": "d25cf692"
      },
      "source": [
        "## Human Detection in Point Cloud Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "oestQ_1M93wh",
      "metadata": {
        "id": "oestQ_1M93wh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_kitti_bin(bin_path):\n",
        "    \"\"\"Load a point cloud file from KITTI's binary format.\"\"\"\n",
        "    point_cloud = np.fromfile(bin_path, dtype=np.float32)\n",
        "    return point_cloud.reshape(-1, 4)  # Reshape to N x 4 matrix (x, y, z, intensity)\n",
        "\n",
        "def voxelize(point_cloud, grid_size=32):\n",
        "    \"\"\"\n",
        "    Convert a point cloud into a fixed-size voxel grid.\n",
        "\n",
        "    Args:\n",
        "    - point_cloud (numpy array): Nx4 point cloud data.\n",
        "    - grid_size (int): Size of the voxel grid.\n",
        "\n",
        "    Returns:\n",
        "    - voxel_grid (numpy array): 3D voxel grid.\n",
        "    \"\"\"\n",
        "    # Define voxel grid boundaries based on the point cloud data\n",
        "    min_bound = point_cloud.min(axis=0)[:3]  # x, y, z min values\n",
        "    max_bound = point_cloud.max(axis=0)[:3]  # x, y, z max values\n",
        "\n",
        "    # Calculate voxel size in each dimension\n",
        "    voxel_size = (max_bound - min_bound) / grid_size\n",
        "\n",
        "    # Convert points to voxel coordinates\n",
        "    voxel_coords = ((point_cloud[:, :3] - min_bound) / voxel_size).astype(int)\n",
        "\n",
        "    # Clip voxel coordinates to grid size\n",
        "    voxel_coords = np.clip(voxel_coords, 0, grid_size-1)\n",
        "\n",
        "    # Create an empty voxel grid\n",
        "    voxel_grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8)\n",
        "\n",
        "    # Fill the voxel grid based on voxel coordinates\n",
        "    voxel_grid[voxel_coords[:, 0], voxel_coords[:, 1], voxel_coords[:, 2]] = 1\n",
        "\n",
        "    return voxel_grid\n",
        "\n",
        "\n",
        "def generate_labels(data_directory, threshold=1000):\n",
        "    \"\"\"\n",
        "    Generate labels for point cloud data based on a voxelization threshold.\n",
        "\n",
        "    Args:\n",
        "    - data_directory (str): Path to the directory containing point cloud .bin files.\n",
        "    - threshold (int): Threshold for filled voxels to label a point cloud as containing a human.\n",
        "\n",
        "    Returns:\n",
        "    - labels (list): List of labels (1 for human, 0 for non-human).\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    for file in sorted(os.listdir(data_directory)):\n",
        "        file_path = os.path.join(data_directory, file)\n",
        "        point_cloud = load_kitti_bin(file_path)\n",
        "        voxel_grid = voxelize(point_cloud)\n",
        "        label = 1 if voxel_grid.sum() > threshold else 0\n",
        "        labels.append(label)\n",
        "    return labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_r4tBcRT5TBK",
      "metadata": {
        "id": "_r4tBcRT5TBK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "class PointCloudDataset(Dataset):\n",
        "    \"\"\"Point Cloud dataset in voxelized format.\"\"\"\n",
        "\n",
        "    def __init__(self, data_directory, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        - data_directory (str): Directory with all the point cloud .bin files.\n",
        "        - labels (list): List of labels for each point cloud.\n",
        "        \"\"\"\n",
        "        self.data_directory = data_directory\n",
        "        self.labels = labels\n",
        "        self.file_list = sorted(os.listdir(data_directory))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load point cloud and convert to voxel grid\n",
        "        file_path = os.path.join(self.data_directory, self.file_list[idx])\n",
        "        point_cloud = load_kitti_bin(file_path)\n",
        "        voxel_grid = voxelize(point_cloud)\n",
        "\n",
        "        # Convert to PyTorch tensor\n",
        "        voxel_tensor = torch.from_numpy(voxel_grid).float().unsqueeze(0)  # Add channel dimension\n",
        "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return voxel_tensor, label_tensor\n",
        "\n",
        "# Create dataset and dataloader\n",
        "data_directory = './data'\n",
        "\n",
        "# Generate labels for the dataset\n",
        "labels = generate_labels(data_directory)\n",
        "num_human_labels = sum(labels)\n",
        "num_total_samples = len(labels)\n",
        "\n",
        "dataset = PointCloudDataset(data_directory, labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "data_train, data_test, labels_train, labels_test = train_test_split(dataset, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(data_train, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(data_test, batch_size=4, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4abd07c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abd07c1",
        "outputId": "5d70870f-856b-444f-f25e-e316c9624cd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Simple3DCNN(\n",
              "  (conv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (fc1): Linear(in_features=32768, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Simple3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simple3DCNN, self).__init__()\n",
        "\n",
        "        # 3D Convolutional layers\n",
        "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Dense layers\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8 * 8, 128)  # After two max pooling, the size becomes 8x8x8\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool3d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool3d(x, 2)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "# Initialize the model\n",
        "model = Simple3DCNN()\n",
        "\n",
        "# Display the model architecture\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b2309c91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2309c91",
        "outputId": "2771993f-5ce0-4a08-8b50-dfe90d362e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0690\n",
            "Epoch [2/5], Loss: 0.0000\n",
            "Epoch [3/5], Loss: 0.0000\n",
            "Epoch [4/5], Loss: 0.0000\n",
            "Epoch [5/5], Loss: 0.0000\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "epochs = 5\n",
        "learning_rate = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Move model to the specified device\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for data, labels in train_dataloader:\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(data)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    average_loss = running_loss / len(train_dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {average_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "461b3b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "461b3b2b",
        "outputId": "1be8f488-1caa-4567-989d-a334c024cac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Store predictions and actual labels\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Evaluate the model on some samples from the training data\n",
        "with torch.no_grad():  # No gradient computation during evaluation\n",
        "    for data, labels in test_dataloader:\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(data)\n",
        "\n",
        "        # Convert predictions to binary labels\n",
        "        predicted_labels = (outputs > 0.5).float()\n",
        "\n",
        "        predictions.extend(predicted_labels.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays for easier comparison\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = np.mean(predictions == true_labels)\n",
        "accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f07e930",
      "metadata": {
        "id": "3f07e930"
      },
      "source": [
        "## Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b2239d48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b2239d48",
        "outputId": "a796876a-a720-4073-afc1-5f816847174a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'simple_3dcnn_weights.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "# Save model weights\n",
        "model_save_path = \"simple_3dcnn_weights.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "model_save_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc61366",
      "metadata": {
        "id": "9cc61366"
      },
      "source": [
        "## Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "76f61156",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76f61156",
        "outputId": "df29893d-6ee9-49c4-a188-b49c846b9755"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Simple3DCNN(\n",
              "  (conv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "  (fc1): Linear(in_features=32768, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "# Load model weights\n",
        "loaded_model = Simple3DCNN()\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()  # Set model to evaluation mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f5a183",
      "metadata": {
        "id": "74f5a183"
      },
      "source": [
        "## Testing the Loaded Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cd477f9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd477f9d",
        "outputId": "f583fb71-9de1-4373-8b28-00c4ea70fc60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "# Test the loaded model on some samples from the training data\n",
        "loaded_predictions = []\n",
        "with torch.no_grad():\n",
        "    for data, _ in test_dataloader:\n",
        "        data = data.to(device)\n",
        "        outputs = loaded_model(data)\n",
        "        predicted_labels = (outputs > 0.5).float()\n",
        "        loaded_predictions.extend(predicted_labels.cpu().numpy())\n",
        "loaded_predictions = np.array(loaded_predictions)\n",
        "loaded_accuracy = np.mean(loaded_predictions == true_labels)\n",
        "loaded_accuracy\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}